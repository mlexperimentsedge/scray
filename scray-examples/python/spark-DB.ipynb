{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "import random\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"Pi\")\n",
    "\n",
    "#sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sparkSession = SparkSession.builder.appName(\"example-pyspark-read-and-write\").getOrCreate()\n",
    "\n",
    "#SparkConf().set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "\n",
    "df = sparkSession.read.parquet('hdfs://172.30.17.145:8020/sla_sql_data/1580137124017/part-00000-b2678865-5b2e-43a7-8428-117b6f435dc5-c000.snappy.parquet')\n",
    "#df.show()\n",
    "#pf = df.toPandas()\n",
    "\n",
    "#df = sqlContext.read.parquet(\"/home/jovyan/work/notebook/flat/000000_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pf = df.limit(1000000).toPandas()\n",
    "#pf=df.filter(df[\"CSERVICE\"]=='PEPPOL').select('*').limit(1000000).dropDuplicates().toPandas()\n",
    "#pf=df.filter(df[\"CSERVICE\"]=='PEPPOL').select('*').limit(1000000).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pf1 = df.filter(df[\"CSERVICE\"]=='PEPPOL').select('*').limit(1000000).dropDuplicates()\n",
    "pf = pf1.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = pf.sort_values('CGLOBALMESSAGEID', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf[\"CSTARTTIME\"] = pd.to_numeric(pf[\"CSTARTTIME\"])\n",
    "#set(pf['CSTARTTIME'].dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.to_datetime(df['CENDTIME']).apply(lambda x: x.date())\n",
    "import datetime\n",
    "readable = datetime.datetime.fromtimestamp(1580983470).isoformat()\n",
    "print(readable)\n",
    "\n",
    "ab = pf.iloc[121]['CENDTIME']\n",
    "\n",
    "import datetime\n",
    "date = datetime.datetime.fromtimestamp(float(ab) / 1e3)\n",
    "\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "import numpy as np\n",
    "pandas_profiling.ProfileReport(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "\n",
    "def get_categories(column):\n",
    "    return np.array(df.select(column).dropDuplicates().dropna().collect())\n",
    "\n",
    "services = get_categories('CSERVICE')\n",
    "receivers = get_categories('CRECEIVERENDPOINTID')\n",
    "senders = get_categories('CSENDERENDPOINTID')\n",
    "receiverprotocols = get_categories('CRECEIVERPROTOCOL')\n",
    "senderprotocols = get_categories('CSENDERPROTOCOL')\n",
    "status = get_categories('CSTATUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from pyhive import hive\n",
    "\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy.engine import create_engine\n",
    "from sqlalchemy.schema import *\n",
    "\n",
    "#engine = create_engine('hive://clspromon-aio01:10000/default')\n",
    "engine = create_engine('hive://172.30.17.145:10000/default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector = inspect(engine)\n",
    "\n",
    "# Get table information\n",
    "#print(inspector.get_table_names())\n",
    "\n",
    "# Get column information\n",
    "row=inspector.get_columns('tables_stage1_p_meta_complete')\n",
    "\n",
    "col = [] \n",
    "for _row in row:\n",
    "    #print(_row['name'])\n",
    "    col.append(_row['name'])\n",
    "\n",
    "#col\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "row =  engine.execute(\"select * from  tables_stage1_p_meta_complete\")\n",
    "meta_p = pd.DataFrame(row)\n",
    "\n",
    "meta_p.columns = col\n",
    "#pyspark.createDataFrame(meta_p).collect()  \n",
    "\n",
    "meta_p.set_index('metricid', inplace=True)\n",
    "#meta_p.set_index('metricid')\n",
    "\n",
    "meta_p['metricid'] = meta_p.index\n",
    "\n",
    "#meta_p.instance.fillna(value=pd.np.nan, inplace=True)\n",
    "meta_p['instance'].replace(pd.np.nan, \"\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta_p.loc[-415304450].__name__\n",
    "#meta_p.iloc[1].service\n",
    "#meta_p\n",
    "#meta_p.loc[meta_p.index[0]].__name__\n",
    "#meta_p.index[1]\n",
    "#meta_p.iloc[1]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta_p.info()\n",
    "dfm = sqlContext.createDataFrame(meta_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "\n",
    "#objects = dfm.select('__name__','instance','product', 'metricid', 'schemaid').dropDuplicates()\n",
    "services = np.array(dfm.select('service').dropDuplicates().dropna().collect())\n",
    "names = np.array(dfm.select('__name__').dropDuplicates().dropna().collect())\n",
    "instances = np.array(dfm.select('instance').dropDuplicates().dropna().collect())\n",
    "products = np.array(dfm.select('product').dropDuplicates().dropna().collect())\n",
    "schemaids = np.array(dfm.select('schemaid').dropDuplicates().dropna().collect())\n",
    "metricid = np.array(dfm.select('metricid').dropDuplicates().dropna().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roles = np.array(dfm.select('role').dropDuplicates().dropna().collect())\n",
    "#roles\n",
    "schemaids.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(str(metricid[1][0]))\n",
    "#names.size\n",
    "#dfm.select('__name__').dropDuplicates().dropna().filter(\"__name__ like '%task%'\").collect()\n",
    "\n",
    "#.filter(dfm.__name__.contains('%b%')).show()\n",
    "#dfm.filter(dfm[\"__name__\"]=='bis_inbox_tasks_running').select(\"*\").collect()\n",
    "#dfm.filter(dfm[\"instance\"]=='clspromsg-ts01:13000').select(\"__name__\").collect()\n",
    "#dfm.filter(dfm[\"instance\"]=='clspromsg-ids01:13000').select(\"__name__\").collect()\n",
    "#dfm.filter(dfm[\"__name__\"]=='bis_jms_message_count').select(\"instance\",'metricid').collect()\n",
    "\n",
    "#la = ['__name__','instance','metricid','schemaid','job','alertname','alertstate','severity' ]\n",
    "#dfm.filter(dfm[\"__name__\"]=='bis_jms_message_count').filter(dfm[\"queue\"]=='DtFTPComponent').filter(dfm[\"instance\"]=='clspromsg-ts01:13000').select(la).collect()\n",
    "\n",
    "#alertes = dfm.filter(dfm[\"__name__\"]=='ALERTS').select(la).limit(200000).toPandas()\n",
    "#alertes.schemaid.size\n",
    "#instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = ['__name__','instance','metricid','schemaid','job','alertname','alertstate','severity' ]\n",
    "\n",
    "alerts = dfm.filter(dfm[\"__name__\"]=='ALERTS').select(la).limit(200000).toPandas()\n",
    "alerts.schemaid.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df[\"hashvalue\"]==id).select('value').distinct().count()\n",
    "\n",
    "#pf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _row in metricid:\n",
    "    id = str(_row[0])\n",
    "    print(id,df.filter(df[\"hashvalue\"]==id).select('value').distinct().count())\n",
    "\n",
    "id = '-1483665529'\n",
    "#id = str(meta_p.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metricid[0]\n",
    "\n",
    "id = 1797174388 \n",
    "#id = '-415304450'\n",
    "\n",
    "#id = -1756241224 #1\n",
    "#id = 1843265645 #24497\n",
    "#id = 852430459 #1\n",
    "#id = -426467024 #22515\n",
    "#id = 6557551 #25097\n",
    "#id = -1466543823 #26614\n",
    "#id = 612749002 #2\n",
    "#id = -547512297 #24905\n",
    "#id = -415304450 #4920\n",
    "#id = 857353913 #1\n",
    "#id = 500298778 #1\n",
    "#id = -349732210 #2\n",
    "#id = 1786297729 #26414\n",
    "\n",
    "#pf=df.filter(df[\"value\"]>'0').filter(df[\"hashvalue\"]=='2012513398').select('date','value').limit(200000).toPandas()\n",
    "#pf=df.filter(df[\"value\"]>'0').filter(df[\"hashvalue\"]==str(metricid[0])).select('date','value').limit(200000).toPandas()\n",
    "#pf=df.filter(df[\"hashvalue\"]==str(metricid[1000][0])).select('date','value').limit(200000).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pf(id):\n",
    "    pf=df.filter(df[\"hashvalue\"]==str(id)).select('date','value').limit(200000).toPandas()\n",
    "    pf = pf.sort_values('date', ascending=True)\n",
    "    pf[\"value\"] = pd.to_numeric(pf[\"value\"])\n",
    "    return pf\n",
    "\n",
    "def get_plot_title(id) :\n",
    "    title = str(id) + \" = \" + meta_p.loc[id].__name__ + \" -> \" + meta_p.loc[id].instance\n",
    "    return title\n",
    "\n",
    "id = alerts.metricid[3]\n",
    "id=612749002\n",
    "\n",
    "pf = get_pf(id)\n",
    "#alertes.metricid.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id=612749002\n",
    "#val = df.filter(df[\"hashvalue\"]==str(id)).select('value')\n",
    "\n",
    "#val.distinct().collect()\n",
    "#val.distinct().count()\n",
    "\n",
    "#val.groupBy('value').count().show()\n",
    "\n",
    "df.filter(df[\"hashvalue\"]==str(id)).filter(df[\"value\"]=='8').select(\"*\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_title = get_plot_title(id)\n",
    "\n",
    "pf.plot(x='date', y='value', title=plot_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()\n",
    "pf = pf.sort_values('date', ascending=True)\n",
    "pf.count()\n",
    "#pf = pf.astype('float')\n",
    "pf[\"value\"] = pd.to_numeric(pf[\"value\"])\n",
    "print(type(pf['value'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "#df.select(\"hashvalue\", F.when(df.hashvalue == 266655713, 1).otherwise(0)).show()\n",
    "#df.select(\"hashvalue\", F.when(df.hashvalue == 266655713, 1).otherwise(0)).show()\n",
    "#df.select(df.hashvalue.between(266655713,266655713)).show()\n",
    "#df.filter(df[\"hashvalue\"]==str(metricid[1][0])).select('date','hashvalue').rdd.flatMap(list).collect()\n",
    "df.filter(df[\"hashvalue\"]==str(metricid[1][0])).select(\"*\").limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metricid[0][0])\n",
    "len(metricid)\n",
    "\n",
    "for row in products:\n",
    "    print(row[0])\n",
    "\n",
    "for id in metricid:\n",
    "    pf=df.filter(df[\"value\"]>'0').filter(df[\"hashvalue\"]==id[0]).select('date','value').limit(200000).toPandas()\n",
    "    pf.describe()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "services.count()\n",
    "products.show()\n",
    "\n",
    "for row in services.rdd.collect():\n",
    "    print(row.service)\n",
    "    \n",
    " \n",
    "#np.array(services.select(\"service\").collect())\n",
    "services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = [] \n",
    "for _row in row:\n",
    "    print(_row['hashvalue'])\n",
    "    hashes.append(_row['hashvalue'])\n",
    "\n",
    "#col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names.select(\"*\").collect()\n",
    "#hashes\n",
    "meta_p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
