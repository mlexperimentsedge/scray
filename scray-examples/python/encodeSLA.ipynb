{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dfBasics\n",
    "import common\n",
    "import encoder\n",
    "import pfAdapt\n",
    "#import charts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCountDF(pf,column,hashes):\n",
    "    dft = pd.DataFrame(columns=[column, 'count'])\n",
    "    i=0\n",
    "    for hash in hashes:\n",
    "        pfall=pf[pf[column] == hash]\n",
    "        num=len(pfall)\n",
    "        if num > 1:\n",
    "            dft.loc[i] = [hash] + [num]\n",
    "            i=i+1\n",
    "    return dft\n",
    "    #return dft.sort_values('count')\n",
    "\n",
    "def usedcolumns(tb,row):\n",
    "    col = []\n",
    "    for column in tb.columns:\n",
    "        if tb.iloc[row][column] == None :\n",
    "            col.append(column)\n",
    "    return col\n",
    "\n",
    "def diffcolumns(tb):\n",
    "    col = []\n",
    "    for column in tb.columns:\n",
    "        if tb.iloc[0][column] != tb.iloc[1][column] :\n",
    "            col.append(column)\n",
    "    return col\n",
    "\n",
    "def printtt():    \n",
    "    col = []\n",
    "    for index, row in tt.iterrows():\n",
    "        tb = pfall[pfall['CGLOBALMESSAGEID'] == row['CGLOBALMESSAGEID']]\n",
    "        for bindex, brow in tb.iterrows():\n",
    "            if pfall.loc[bindex]['CSLADELIVERYTIME'] < 0 :\n",
    "                #print (str(index) + ' ' + str(bindex))\n",
    "                col.append(bindex)\n",
    "    return col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astype(pfall,selected,newtype):\n",
    "    for each in selected:\n",
    "        pfall[each] = pfall[each].astype(newtype)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = [ 'CSTATUS', 'CSERVICE',\\\n",
    "        'CSENDERPROTOCOL', 'CSENDERENDPOINTID',\\\n",
    "        'CRECEIVERPROTOCOL', 'CRECEIVERENDPOINTID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodepfall(pfall,number):\n",
    "    print('1')\n",
    "    astype(pfall,['CSTARTTIME','CENDTIME','CSLATAT','CMESSAGETAT2','CSLADELIVERYTIME','CINBOUNDSIZE'] ,int) \n",
    "    #del(pfall['CSLABILLINGMONTH'])\n",
    "    pfall['CGLOBALMESSAGEID'] = pfall['CGLOBALMESSAGEID'].apply(hash)\n",
    "    print('1b')\n",
    "    ac = pd.unique(pfall['CGLOBALMESSAGEID'])\n",
    "    print('2')\n",
    "    tt = getCountDF(pfall,'CGLOBALMESSAGEID',ac)\n",
    "    print('3')\n",
    "    col = printtt() \n",
    "    print('4')\n",
    "    pfall = pfall.drop(col)\n",
    "    print('5')\n",
    "    astype(pfall,selected,str) \n",
    "    encoder.encode(pfall,selected)\n",
    "    \n",
    "    print('6')\n",
    "    pfall = pfall.drop_duplicates()\n",
    "    print('7')\n",
    "    pfall.to_parquet('/tmp/sla_' + number + '.parquet', engine='fastparquet', compression='GZIP')\n",
    "    return pfall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['CGLOBALMESSAGEID', 'CSTARTTIME', 'CENDTIME', 'CSTATUS', 'CSERVICE',\\\n",
    "       'CSLABILLINGMONTH', 'CSENDERPROTOCOL', 'CSENDERENDPOINTID',\\\n",
    "       'CINBOUNDSIZE', 'CRECEIVERPROTOCOL', 'CRECEIVERENDPOINTID', 'CSLATAT',\\\n",
    "       'CMESSAGETAT2', 'CSLADELIVERYTIME']\n",
    "# withot 'CSLABILLINGMONTH'\n",
    "def get_columns_2():\n",
    "    columns = ['CGLOBALMESSAGEID', 'CSTARTTIME', 'CENDTIME', 'CSTATUS', 'CSERVICE',\\\n",
    "            'CSENDERPROTOCOL', 'CSENDERENDPOINTID',\\\n",
    "           'CINBOUNDSIZE', 'CRECEIVERPROTOCOL', 'CRECEIVERENDPOINTID', 'CSLATAT',\\\n",
    "           'CMESSAGETAT2', 'CSLADELIVERYTIME']\n",
    "    return columns\n",
    "columns = get_columns_2()\n",
    "#to count messages sent\n",
    "#columns = [ 'CSTARTTIME', 'CSENDERENDPOINTID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkSession = dfBasics.getSparkSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(pfall), len(ac)\n",
    "#pfall.head()\n",
    "#pfall.dtypes\n",
    "#len(mdcountsall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pfall[pfall['CGLOBALMESSAGEID'] == mdcountsall.index.get_level_values(0)[0]]\n",
    "#pfall['CGLOBALMESSAGEID'] == -9209718302575659389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(pfall[pfall['CSLADELIVERYTIME'] == -1])\n",
    "#mdcountsall.index.get_level_values(0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printtt(tt):    \n",
    "    col = []\n",
    "    #col2 = []\n",
    "    i = 0\n",
    "    for index in tt.index.get_level_values(0):\n",
    "        tb = pfall[pfall['CGLOBALMESSAGEID'] == index]\n",
    "        findex = []\n",
    "        for bindex, brow in tb.iterrows():   \n",
    "            if pfall.loc[bindex]['CSLADELIVERYTIME'] < 0 :\n",
    "                #print (str(index) + ' ' + str(bindex))\n",
    "                #col.append(bindex)\n",
    "                findex.append(bindex)\n",
    "        if(len(findex) == 1):\n",
    "            col.append(findex[0])   \n",
    "        elif(len(findex) == 2):\n",
    "            if (pfall.iloc[findex[0]]['CENDTIME'] > pfall.iloc[findex[1]]['CENDTIME']):\n",
    "                col.append(findex[0])\n",
    "            else:\n",
    "                col.append(findex[1])\n",
    "        else:\n",
    "            if (tb.iloc[0]['CMESSAGETAT2'] > tb.iloc[1]['CMESSAGETAT2']):\n",
    "                col.append(tb.index[0])\n",
    "            else:\n",
    "                col.append(tb.index[1]) \n",
    "    return col\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pfall.iloc[g[1][0]]['CENDTIME'],pfall.iloc[g[1][1]]['CENDTIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(f), len(mdcountsall),f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read timestamps from file\n",
    "with open(\"/tmp/slatimestamps.txt\", \"r\") as file:\n",
    "    lines = file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getencodedpfall(line) :\n",
    "    df = sparkSession.read.parquet('hdfs://172.30.17.145:8020/sla_sql_data/' + line +  '*/*').select(columns).dropDuplicates()\n",
    "    #print('df.toPandas')\n",
    "    pfall = df.toPandas() \n",
    "    #print('1')\n",
    "    astype(pfall,['CSTARTTIME','CENDTIME','CSLATAT','CMESSAGETAT2','CSLADELIVERYTIME','CINBOUNDSIZE'] ,int) \n",
    "    #del(pfall['CSLABILLINGMONTH'])\n",
    "    pfall['CGLOBALMESSAGEID'] = pfall['CGLOBALMESSAGEID'].apply(hash)\n",
    "    #print('1b')\n",
    "    #ac = pd.unique(pfall['CGLOBALMESSAGEID'])\n",
    "    mdcountsall = pfall.groupby(['CGLOBALMESSAGEID','CSTATUS'])['CSTARTTIME'].count()\n",
    "    mdcountsall = mdcountsall[mdcountsall > 1]\n",
    "    f = printtt(mdcountsall)\n",
    "    pfall = pfall.drop(f)\n",
    "    astype(pfall,selected,str) \n",
    "    encoder.encode(pfall,selected)\n",
    "    return pfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line = lines[0]\n",
    "#pfall = getencodedpfall(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    pfall = getencodedpfall(line)\n",
    "    pfall.to_parquet('/tmp/sla_' + line + '.parquet', engine='fastparquet', compression='GZIP')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
