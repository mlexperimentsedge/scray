{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = \"http://172.30.12.56:3128\" \n",
    "os.environ['https_proxy'] = \"https://172.30.12.56:3128\"       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.12\n",
      "  latest version: 4.8.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - fastparquet\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    fastparquet-0.3.2          |   py37hc1659b7_0         249 KB  conda-forge\n",
      "    thrift-0.11.0              |py37he1b5a44_1001         109 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         358 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  fastparquet        conda-forge/linux-64::fastparquet-0.3.2-py37hc1659b7_0\n",
      "  thrift             conda-forge/linux-64::thrift-0.11.0-py37he1b5a44_1001\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "fastparquet-0.3.2    | 249 KB    | ##################################### | 100% \n",
      "thrift-0.11.0        | 109 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.12\n",
      "  latest version: 4.8.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - pyhive\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    cyrus-sasl-2.1.27          |       he38ecfd_0         232 KB  conda-forge\n",
      "    future-0.18.2              |           py37_0         711 KB  conda-forge\n",
      "    libntlm-1.4                |    h14c3975_1002          32 KB  conda-forge\n",
      "    pyhive-0.6.1               |           py37_0          81 KB  defaults\n",
      "    sasl-0.2.1                 |py37he1b5a44_1001          56 KB  conda-forge\n",
      "    thrift_sasl-0.3.0          |py37h516909a_1001          13 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         1.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cyrus-sasl         conda-forge/linux-64::cyrus-sasl-2.1.27-he38ecfd_0\n",
      "  future             conda-forge/linux-64::future-0.18.2-py37_0\n",
      "  libntlm            conda-forge/linux-64::libntlm-1.4-h14c3975_1002\n",
      "  pyhive             pkgs/main/linux-64::pyhive-0.6.1-py37_0\n",
      "  sasl               conda-forge/linux-64::sasl-0.2.1-py37he1b5a44_1001\n",
      "  thrift_sasl        conda-forge/linux-64::thrift_sasl-0.3.0-py37h516909a_1001\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pyhive-0.6.1         | 81 KB     | ##################################### | 100% \n",
      "sasl-0.2.1           | 56 KB     | ##################################### | 100% \n",
      "cyrus-sasl-2.1.27    | 232 KB    | ##################################### | 100% \n",
      "thrift_sasl-0.3.0    | 13 KB     | ##################################### | 100% \n",
      "libntlm-1.4          | 32 KB     | ##################################### | 100% \n",
      "future-0.18.2        | 711 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.12\n",
      "  latest version: 4.8.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas-profiling\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    astroid-2.3.3              |           py37_1         279 KB  conda-forge\n",
      "    astropy-4.0                |   py37h516909a_0         7.5 MB  conda-forge\n",
      "    confuse-1.0.0              |             py_0          19 KB  conda-forge\n",
      "    dbus-1.13.6                |       he372182_0         602 KB  conda-forge\n",
      "    expat-2.2.5                |    he1b5a44_1004         191 KB  conda-forge\n",
      "    gst-plugins-base-1.14.5    |       h0935bb2_0         6.8 MB  conda-forge\n",
      "    gstreamer-1.14.5           |       h36ae1b5_0         4.5 MB  conda-forge\n",
      "    htmlmin-0.1.12             |             py_1          21 KB  conda-forge\n",
      "    hypothesis-5.2.0           |             py_0         179 KB  conda-forge\n",
      "    isort-4.3.21               |           py37_0          64 KB  conda-forge\n",
      "    lazy-object-proxy-1.4.3    |   py37h516909a_0          27 KB  conda-forge\n",
      "    matplotlib-3.1.1           |   py37h5429711_0         5.0 MB  defaults\n",
      "    mccabe-0.6.1               |             py_1           8 KB  conda-forge\n",
      "    missingno-0.4.2            |             py_0          12 KB  conda-forge\n",
      "    pandas-profiling-2.4.0     |             py_0         134 KB  conda-forge\n",
      "    phik-0.9.8                 |             py_0         584 KB  conda-forge\n",
      "    pluggy-0.12.0              |             py_0          18 KB  conda-forge\n",
      "    py-1.8.1                   |             py_0          66 KB  conda-forge\n",
      "    pylint-2.4.4               |           py37_0         424 KB  conda-forge\n",
      "    pyqt-5.9.2                 |   py37hcca6a23_4         5.7 MB  conda-forge\n",
      "    pytest-5.3.4               |           py37_0         370 KB  conda-forge\n",
      "    pytest-arraydiff-0.3       |             py_0          11 KB  conda-forge\n",
      "    pytest-astropy-0.7.0       |             py_0           6 KB  conda-forge\n",
      "    pytest-astropy-header-0.1.2|             py_0          10 KB  conda-forge\n",
      "    pytest-doctestplus-0.4.0   |             py_0          16 KB  conda-forge\n",
      "    pytest-openfiles-0.4.0     |             py_0           9 KB  conda-forge\n",
      "    pytest-pylint-0.14.1       |             py_0           9 KB  conda-forge\n",
      "    pytest-remotedata-0.3.1    |             py_0          11 KB  conda-forge\n",
      "    pytest-runner-5.2          |             py_0           9 KB  conda-forge\n",
      "    qt-5.9.7                   |       h52cfd70_2        85.9 MB  conda-forge\n",
      "    sip-4.19.8                 |   py37hf484d3e_0         274 KB  defaults\n",
      "    typed-ast-1.4.1            |   py37h516909a_0         205 KB  conda-forge\n",
      "    wrapt-1.11.2               |   py37h516909a_0          46 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       118.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  astroid            conda-forge/linux-64::astroid-2.3.3-py37_1\n",
      "  astropy            conda-forge/linux-64::astropy-4.0-py37h516909a_0\n",
      "  confuse            conda-forge/noarch::confuse-1.0.0-py_0\n",
      "  dbus               conda-forge/linux-64::dbus-1.13.6-he372182_0\n",
      "  expat              conda-forge/linux-64::expat-2.2.5-he1b5a44_1004\n",
      "  gst-plugins-base   conda-forge/linux-64::gst-plugins-base-1.14.5-h0935bb2_0\n",
      "  gstreamer          conda-forge/linux-64::gstreamer-1.14.5-h36ae1b5_0\n",
      "  htmlmin            conda-forge/noarch::htmlmin-0.1.12-py_1\n",
      "  hypothesis         conda-forge/noarch::hypothesis-5.2.0-py_0\n",
      "  isort              conda-forge/linux-64::isort-4.3.21-py37_0\n",
      "  lazy-object-proxy  conda-forge/linux-64::lazy-object-proxy-1.4.3-py37h516909a_0\n",
      "  matplotlib         pkgs/main/linux-64::matplotlib-3.1.1-py37h5429711_0\n",
      "  mccabe             conda-forge/noarch::mccabe-0.6.1-py_1\n",
      "  missingno          conda-forge/noarch::missingno-0.4.2-py_0\n",
      "  pandas-profiling   conda-forge/noarch::pandas-profiling-2.4.0-py_0\n",
      "  phik               conda-forge/noarch::phik-0.9.8-py_0\n",
      "  pluggy             conda-forge/noarch::pluggy-0.12.0-py_0\n",
      "  py                 conda-forge/noarch::py-1.8.1-py_0\n",
      "  pylint             conda-forge/linux-64::pylint-2.4.4-py37_0\n",
      "  pyqt               conda-forge/linux-64::pyqt-5.9.2-py37hcca6a23_4\n",
      "  pytest             conda-forge/linux-64::pytest-5.3.4-py37_0\n",
      "  pytest-arraydiff   conda-forge/noarch::pytest-arraydiff-0.3-py_0\n",
      "  pytest-astropy     conda-forge/noarch::pytest-astropy-0.7.0-py_0\n",
      "  pytest-astropy-he~ conda-forge/noarch::pytest-astropy-header-0.1.2-py_0\n",
      "  pytest-doctestplus conda-forge/noarch::pytest-doctestplus-0.4.0-py_0\n",
      "  pytest-openfiles   conda-forge/noarch::pytest-openfiles-0.4.0-py_0\n",
      "  pytest-pylint      conda-forge/noarch::pytest-pylint-0.14.1-py_0\n",
      "  pytest-remotedata  conda-forge/noarch::pytest-remotedata-0.3.1-py_0\n",
      "  pytest-runner      conda-forge/noarch::pytest-runner-5.2-py_0\n",
      "  qt                 conda-forge/linux-64::qt-5.9.7-h52cfd70_2\n",
      "  sip                pkgs/main/linux-64::sip-4.19.8-py37hf484d3e_0\n",
      "  typed-ast          conda-forge/linux-64::typed-ast-1.4.1-py37h516909a_0\n",
      "  wrapt              conda-forge/linux-64::wrapt-1.11.2-py37h516909a_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytest-astropy-heade | 10 KB     | ##################################### | 100% \n",
      "pytest-remotedata-0. | 11 KB     | ##################################### | 100% \n",
      "matplotlib-3.1.1     | 5.0 MB    | ##################################### | 100% \n",
      "astroid-2.3.3        | 279 KB    | ##################################### | 100% \n",
      "pytest-arraydiff-0.3 | 11 KB     | ##################################### | 100% \n",
      "pyqt-5.9.2           | 5.7 MB    | ##################################### | 100% \n",
      "pytest-doctestplus-0 | 16 KB     | ##################################### | 100% \n",
      "pytest-runner-5.2    | 9 KB      | ##################################### | 100% \n",
      "isort-4.3.21         | 64 KB     | ##################################### | 100% \n",
      "expat-2.2.5          | 191 KB    | ##################################### | 100% \n",
      "pytest-pylint-0.14.1 | 9 KB      | ##################################### | 100% \n",
      "dbus-1.13.6          | 602 KB    | ##################################### | 100% \n",
      "phik-0.9.8           | 584 KB    | ##################################### | 100% \n",
      "htmlmin-0.1.12       | 21 KB     | ##################################### | 100% \n",
      "mccabe-0.6.1         | 8 KB      | ##################################### | 100% \n",
      "py-1.8.1             | 66 KB     | ##################################### | 100% \n",
      "qt-5.9.7             | 85.9 MB   | ##################################### | 100% \n",
      "pytest-astropy-0.7.0 | 6 KB      | ##################################### | 100% \n",
      "confuse-1.0.0        | 19 KB     | ##################################### | 100% \n",
      "pytest-openfiles-0.4 | 9 KB      | ##################################### | 100% \n",
      "gstreamer-1.14.5     | 4.5 MB    | ##################################### | 100% \n",
      "astropy-4.0          | 7.5 MB    | ##################################### | 100% \n",
      "sip-4.19.8           | 274 KB    | ##################################### | 100% \n",
      "hypothesis-5.2.0     | 179 KB    | ##################################### | 100% \n",
      "pandas-profiling-2.4 | 134 KB    | ##################################### | 100% \n",
      "pylint-2.4.4         | 424 KB    | ##################################### | 100% \n",
      "wrapt-1.11.2         | 46 KB     | ##################################### | 100% \n",
      "lazy-object-proxy-1. | 27 KB     | ##################################### | 100% \n",
      "typed-ast-1.4.1      | 205 KB    | ##################################### | 100% \n",
      "pytest-5.3.4         | 370 KB    | ##################################### | 100% \n",
      "gst-plugins-base-1.1 | 6.8 MB    | ##################################### | 100% \n",
      "missingno-0.4.2      | 12 KB     | ##################################### | 100% \n",
      "pluggy-0.12.0        | 18 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "#pip install fastparquet\n",
    "!conda install -y -c conda-forge fastparquet\n",
    "!conda install -y pyhive\n",
    "!conda install -y -c conda-forge pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /root/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - vaex\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    arrow-cpp-0.12.1           |   py37h0e61e49_0         6.9 MB  conda-forge\n",
      "    boost-cpp-1.68.0           |    h11c811c_1000        20.5 MB  conda-forge\n",
      "    cachetools-3.1.1           |             py_0          11 KB  conda-forge\n",
      "    libprotobuf-3.6.1          |    hdbcaa40_1001         4.0 MB  conda-forge\n",
      "    parquet-cpp-1.5.1          |                4           3 KB  conda-forge\n",
      "    pyarrow-0.12.1             |   py37hbbcf98d_0         2.2 MB  conda-forge\n",
      "    thrift-cpp-0.12.0          |    h0a07b25_1002         2.4 MB  conda-forge\n",
      "    vaex-2.5.0                 |             py_0           9 KB  conda-forge\n",
      "    vaex-arrow-0.4.2           |             py_0           9 KB  conda-forge\n",
      "    vaex-astro-0.6.1           |             py_1          12 KB  conda-forge\n",
      "    vaex-ml-0.7.0              |             py_0          74 KB  conda-forge\n",
      "    vaex-server-0.2.1          |             py_0           4 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        36.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  arrow-cpp          conda-forge/linux-64::arrow-cpp-0.12.1-py37h0e61e49_0\n",
      "  boost-cpp          conda-forge/linux-64::boost-cpp-1.68.0-h11c811c_1000\n",
      "  cachetools         conda-forge/noarch::cachetools-3.1.1-py_0\n",
      "  libprotobuf        conda-forge/linux-64::libprotobuf-3.6.1-hdbcaa40_1001\n",
      "  parquet-cpp        conda-forge/noarch::parquet-cpp-1.5.1-4\n",
      "  pyarrow            conda-forge/linux-64::pyarrow-0.12.1-py37hbbcf98d_0\n",
      "  thrift-cpp         conda-forge/linux-64::thrift-cpp-0.12.0-h0a07b25_1002\n",
      "  vaex               conda-forge/noarch::vaex-2.5.0-py_0\n",
      "  vaex-arrow         conda-forge/noarch::vaex-arrow-0.4.2-py_0\n",
      "  vaex-astro         conda-forge/noarch::vaex-astro-0.6.1-py_1\n",
      "  vaex-ml            conda-forge/noarch::vaex-ml-0.7.0-py_0\n",
      "  vaex-server        conda-forge/noarch::vaex-server-0.2.1-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "cachetools-3.1.1     | 11 KB     | ##################################### | 100% \n",
      "libprotobuf-3.6.1    | 4.0 MB    | ##################################### | 100% \n",
      "boost-cpp-1.68.0     | 20.5 MB   | ##################################### | 100% \n",
      "pyarrow-0.12.1       | 2.2 MB    | ##################################### | 100% \n",
      "arrow-cpp-0.12.1     | 6.9 MB    | ##################################### | 100% \n",
      "vaex-astro-0.6.1     | 12 KB     | ##################################### | 100% \n",
      "vaex-arrow-0.4.2     | 9 KB      | ##################################### | 100% \n",
      "thrift-cpp-0.12.0    | 2.4 MB    | ##################################### | 100% \n",
      "vaex-ml-0.7.0        | 74 KB     | ##################################### | 100% \n",
      "vaex-2.5.0           | 9 KB      | ##################################### | 100% \n",
      "parquet-cpp-1.5.1    | 3 KB      | ##################################### | 100% \n",
      "vaex-server-0.2.1    | 4 KB      | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -y -c conda-forge vaex\n",
    "#!conda install -y -c conda-forge vaex-hdf5\n",
    "#!conda uninstall -y -c conda-forge pyarrow\n",
    "#!conda install -y -c conda-forge pyarrow=0.12.1\n",
    "#!conda install -c conda-forge --quiet -y arrow-cpp=0.12.* pyarrow\n",
    "#!conda install -y -c conda-forge dask\n",
    "#!conda install -y -c conda-forge vaex-jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaex-hdf5==0.5.6 in /root/anaconda3/lib/python3.7/site-packages (0.5.6)\n",
      "Requirement already satisfied: s3fs<0.3 in /root/anaconda3/lib/python3.7/site-packages (from vaex-hdf5==0.5.6) (0.2.2)\n",
      "Requirement already satisfied: h5py>=2.9 in /root/anaconda3/lib/python3.7/site-packages (from vaex-hdf5==0.5.6) (2.9.0)\n",
      "Requirement already satisfied: vaex-core<2,>=1.3.0 in /root/anaconda3/lib/python3.7/site-packages (from vaex-hdf5==0.5.6) (1.4.0)\n",
      "Requirement already satisfied: boto3>=1.9.91 in /root/anaconda3/lib/python3.7/site-packages (from s3fs<0.3->vaex-hdf5==0.5.6) (1.10.48)\n",
      "Requirement already satisfied: six>=1.12.0 in /root/anaconda3/lib/python3.7/site-packages (from s3fs<0.3->vaex-hdf5==0.5.6) (1.12.0)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /root/anaconda3/lib/python3.7/site-packages (from s3fs<0.3->vaex-hdf5==0.5.6) (1.13.48)\n",
      "Requirement already satisfied: numpy>=1.7 in /root/anaconda3/lib/python3.7/site-packages (from h5py>=2.9->vaex-hdf5==0.5.6) (1.16.2)\n",
      "Requirement already satisfied: progressbar2 in /root/anaconda3/lib/python3.7/site-packages (from vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (3.47.0)\n",
      "Requirement already satisfied: psutil>=1.2.1 in /root/anaconda3/lib/python3.7/site-packages (from vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (5.6.1)\n",
      "Requirement already satisfied: pyyaml in /root/anaconda3/lib/python3.7/site-packages (from vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (5.1)\n",
      "Requirement already satisfied: pandas in /root/anaconda3/lib/python3.7/site-packages (from vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (0.24.2)\n",
      "Requirement already satisfied: dask[array] in /root/anaconda3/lib/python3.7/site-packages (from vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (1.1.4)\n",
      "Requirement already satisfied: astropy>=2 in /root/anaconda3/lib/python3.7/site-packages (from vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (3.1.2)\n",
      "Requirement already satisfied: future>=0.15.2 in /root/anaconda3/lib/python3.7/site-packages (from vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (0.17.1)\n",
      "Requirement already satisfied: tabulate>=0.8.3 in /root/anaconda3/lib/python3.7/site-packages (from vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (0.8.6)\n",
      "Requirement already satisfied: requests in /root/anaconda3/lib/python3.7/site-packages (from vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (2.21.0)\n",
      "Requirement already satisfied: cloudpickle in /root/anaconda3/lib/python3.7/site-packages (from vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (0.8.0)\n",
      "Requirement already satisfied: aplus in /root/anaconda3/lib/python3.7/site-packages (from vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (0.11.0)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /root/anaconda3/lib/python3.7/site-packages (from boto3>=1.9.91->s3fs<0.3->vaex-hdf5==0.5.6) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /root/anaconda3/lib/python3.7/site-packages (from boto3>=1.9.91->s3fs<0.3->vaex-hdf5==0.5.6) (0.9.4)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20 in /root/anaconda3/lib/python3.7/site-packages (from botocore>=1.12.91->s3fs<0.3->vaex-hdf5==0.5.6) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /root/anaconda3/lib/python3.7/site-packages (from botocore>=1.12.91->s3fs<0.3->vaex-hdf5==0.5.6) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /root/anaconda3/lib/python3.7/site-packages (from botocore>=1.12.91->s3fs<0.3->vaex-hdf5==0.5.6) (0.14)\n",
      "Requirement already satisfied: python-utils>=2.3.0 in /root/anaconda3/lib/python3.7/site-packages (from progressbar2->vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (2.3.0)\n",
      "Requirement already satisfied: pytz>=2011k in /root/anaconda3/lib/python3.7/site-packages (from pandas->vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (2018.9)\n",
      "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /root/anaconda3/lib/python3.7/site-packages (from dask[array]->vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (0.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/lib/python3.7/site-packages (from requests->vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /root/anaconda3/lib/python3.7/site-packages (from requests->vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /root/anaconda3/lib/python3.7/site-packages (from requests->vaex-core<2,>=1.3.0->vaex-hdf5==0.5.6) (3.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:MainThread:vaex:error opening '/root/.vaex/data/helmi-dezeeuw-2000-10p.hdf5'\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Could not open file: /root/.vaex/data/helmi-dezeeuw-2000-10p.hdf5, did you install vaex-hdf5? Is the format supported?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a389b76b6f97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvaex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#df = vaex.open('/root/.vaex/data/helmi-dezeeuw-2000-10p.hdf5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/vaex/__init__.py\u001b[0m in \u001b[0;36mexample\u001b[0;34m(download)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"helmi-dezeeuw-2000-10p.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvaex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelmi_de_zeeuw_10percent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/vaex/datasets.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, force_download)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwget_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/vaex/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, convert, shuffle, copy_index, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not open file: {}, did you install vaex-hdf5? Is the format supported?'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not open file: {}, it does not exist?'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Could not open file: /root/.vaex/data/helmi-dezeeuw-2000-10p.hdf5, did you install vaex-hdf5? Is the format supported?"
     ]
    }
   ],
   "source": [
    "import vaex\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "df = vaex.example()\n",
    "#df = vaex.open('/root/.vaex/data/helmi-dezeeuw-2000-10p.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n",
      "Enabling notebook extension bqplot/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n",
      "Enabling notebook extension ipyvolume/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n",
      "Enabling notebook extension jupyter-matplotlib/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n",
      "Enabling notebook extension jupyter-leaflet/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!jupyter nbextension enable --sys-prefix --py widgetsnbextension\n",
    "!jupyter nbextension enable --sys-prefix --py bqplot\n",
    "!jupyter nbextension enable --sys-prefix --py ipyvolume\n",
    "!jupyter nbextension enable --sys-prefix --py ipympl\n",
    "!jupyter nbextension enable --sys-prefix --py ipyleaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.12\n",
      "  latest version: 4.8.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - pyspark\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    py4j-0.10.7                |             py_1         177 KB  conda-forge\n",
      "    pyspark-2.4.4              |             py_0       204.9 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       205.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  py4j               conda-forge/noarch::py4j-0.10.7-py_1\n",
      "  pyspark            conda-forge/noarch::pyspark-2.4.4-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "py4j-0.10.7          | 177 KB    | ##################################### | 100% \n",
      "pyspark-2.4.4        | 204.9 MB  | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "#!conda install -y -c conda-forge findspark\n",
    "!conda install -y -c conda-forge pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin   dev  home  lib64\tmnt  proc  run\t srv  tmp  var\r\n",
      "boot  etc  lib\t media\topt  root  sbin  sys  usr\r\n"
     ]
    }
   ],
   "source": [
    "#!pyspark\n",
    "!ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2f511271740d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Below code is Spark 2+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m                     \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mJVM\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\"\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_launch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36m_launch_gateway\u001b[0;34m(conf, insecure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "# Start pyspark via provided command\n",
    "import pyspark\n",
    "\n",
    "# Below code is Spark 2+\n",
    "spark = pyspark.sql.SparkSession.builder.appName('test').getOrCreate()\n",
    "\n",
    "spark.range(10).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Couldn't find Spark, make sure SPARK_HOME env is set or Spark is in an expected location (e.g. from homebrew installation).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-00438825581b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfindspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/findspark.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mspark_home\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mspark_home\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpython_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/findspark.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mspark_home\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         raise ValueError(\"Couldn't find Spark, make sure SPARK_HOME env is set\"\n\u001b[0m\u001b[1;32m     34\u001b[0m                          \" or Spark is in an expected location (e.g. from homebrew installation).\")\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Couldn't find Spark, make sure SPARK_HOME env is set or Spark is in an expected location (e.g. from homebrew installation)."
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from hdfs import InsecureClient\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Webhdfs by providing hdfs host ip and webhdfs port (50070 by default)\n",
    "#client_hdfs = InsecureClient('http://' + os.environ['localhost'] + ':50070')\n",
    "#os.environ['clspromon-aio01']\n",
    "#client_hdfs = InsecureClient('http://' + os.environ['clspromon-aio01'] + ':9870')\n",
    "client_hdfs = InsecureClient('http://clspromon-aio01.txx.seeburger.de:9870')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "HdfsError",
     "evalue": "b'<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\\n<html><head>\\n<title>502 Proxy Error</title>\\n</head><body>\\n<h1>Proxy Error</h1>\\n<p>The proxy server received an invalid\\r\\nresponse from an upstream server.<br />\\r\\nThe proxy server could not handle the request <em><a href=\"http://clspromon-aio01.txx.seeburger.de:9870/webhdfs/v1/user/admin/stage3/metrics/BIC%20Client/000000_0_copy_1?user.name=root&amp;offset=0&amp;op=OPEN\">GET&nbsp;http://clspromon-aio01.txx.seeburger.de:9870/webhdfs/v1/user/admin/stage3/metrics/BIC%20Client/000000_0_copy_1?user.name=root&amp;offset=0&amp;op=OPEN</a></em>.<p>\\nReason: <strong>DNS lookup failure for: clspromon-aio01.txx.seeburger.de</strong></p></p>\\n</body></html>\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHdfsError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b7611cdcae3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'export HADOOP_USER_NAME=admin '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mclient_hdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/user/admin/stage3/metrics/BIC Client/000000_0_copy_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/venv/lib/python3.6/site-packages/hdfs/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, hdfs_path, offset, length, buffer_size, encoding, chunk_size, delimiter, progress)\u001b[0m\n\u001b[1;32m    684\u001b[0m       \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m       \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m       \u001b[0mbuffersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m     )\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/venv/lib/python3.6/site-packages/hdfs/client.py\u001b[0m in \u001b[0;36mapi_handler\u001b[0;34m(client, hdfs_path, data, strict, **params)\u001b[0m\n\u001b[1;32m    116\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'RetriableException'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'StandbyException'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHdfsError\u001b[0m: b'<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\\n<html><head>\\n<title>502 Proxy Error</title>\\n</head><body>\\n<h1>Proxy Error</h1>\\n<p>The proxy server received an invalid\\r\\nresponse from an upstream server.<br />\\r\\nThe proxy server could not handle the request <em><a href=\"http://clspromon-aio01.txx.seeburger.de:9870/webhdfs/v1/user/admin/stage3/metrics/BIC%20Client/000000_0_copy_1?user.name=root&amp;offset=0&amp;op=OPEN\">GET&nbsp;http://clspromon-aio01.txx.seeburger.de:9870/webhdfs/v1/user/admin/stage3/metrics/BIC%20Client/000000_0_copy_1?user.name=root&amp;offset=0&amp;op=OPEN</a></em>.<p>\\nReason: <strong>DNS lookup failure for: clspromon-aio01.txx.seeburger.de</strong></p></p>\\n</body></html>\\n'"
     ]
    }
   ],
   "source": [
    "!export HADOOP_USER_NAME=admin \n",
    "with client_hdfs.read('/user/admin/stage3/metrics/BIC Client/000000_0_copy_1', encoding = 'utf-8') as reader:\n",
    "    df = pd.read_csv(reader,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Passed non-file path: example_fp.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0447e19b7170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'example_fp.parquet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pyarrow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/jupyter/venv/lib/python3.6/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/jupyter/venv/lib/python3.6/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_pandas_metadata'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             result = self.api.parquet.read_table(path, columns=columns,\n\u001b[0;32m--> 131\u001b[0;31m                                                  **kwargs).to_pandas()\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/venv/lib/python3.6/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size)\u001b[0m\n\u001b[1;32m   1272\u001b[0m                             \u001b[0mread_dictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_dictionary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m                             \u001b[0mbuffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m                             filesystem=filesystem, filters=filters)\n\u001b[0m\u001b[1;32m   1275\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m         pf = ParquetFile(source, metadata=metadata,\n",
      "\u001b[0;32m~/jupyter/venv/lib/python3.6/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_paths, filesystem, schema, metadata, split_row_groups, validate_schema, filters, metadata_nthreads, read_dictionary, memory_map, buffer_size)\u001b[0m\n\u001b[1;32m   1028\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_manifest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m              \u001b[0mpath_or_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_nthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata_nthreads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m              \u001b[0mopen_file_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_dataset_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m         )\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/venv/lib/python3.6/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36m_make_manifest\u001b[0;34m(path_or_paths, fs, pathsep, metadata_nthreads, open_file_func)\u001b[0m\n\u001b[1;32m   1227\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m                 raise IOError('Passed non-file path: {0}'\n\u001b[0;32m-> 1229\u001b[0;31m                               .format(path))\n\u001b[0m\u001b[1;32m   1230\u001b[0m             \u001b[0mpiece\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParquetDatasetPiece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_file_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen_file_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0mpieces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiece\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Passed non-file path: example_fp.parquet"
     ]
    }
   ],
   "source": [
    "pd.read_parquet('/user/admin/stage3/metrics/BIC Client/000000_0_copy_1', engine='pyarrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
