{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo: loads file with all messages (CSTARTTIME, CSENDERENDPOINTID, ymdhm )\n",
    "# show some charts, anomaly detection with LSTM autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n",
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "import dfBasics\n",
    "import common\n",
    "import encoder\n",
    "import pfAdapt\n",
    "import charts\n",
    "import anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pfall = pd.read_parquet('/tmp/msgsenders_0702.parquet', engine='fastparquet')\n",
    "pfall = pd.read_parquet('/tmp/sla_1580137124017.parquet', engine='pyarrow')\n",
    "#pfall = pd.read_parquet('/tmp/sla_1580199488133.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CGLOBALMESSAGEID       int64\n",
       "CSTARTTIME             int64\n",
       "CENDTIME               int64\n",
       "CSTATUS                int64\n",
       "CSERVICE               int64\n",
       "CSENDERPROTOCOL        int64\n",
       "CSENDERENDPOINTID      int64\n",
       "CINBOUNDSIZE           int64\n",
       "CRECEIVERPROTOCOL      int64\n",
       "CRECEIVERENDPOINTID    int64\n",
       "CSLATAT                int64\n",
       "CMESSAGETAT2           int64\n",
       "CSLADELIVERYTIME       int64\n",
       "year                   int64\n",
       "month                  int64\n",
       "day                    int64\n",
       "hour                   int64\n",
       "minute                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adddatecolumns(pfall,pfall,'CSTARTTIME')\n",
    "pfall.dtypes\n",
    "#pfall.dtypes\n",
    "#!ls -l /tmp/sla_*.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import time\n",
    "import datetime as dt\n",
    "import calendar\n",
    "import pytz\n",
    "de = pytz.timezone('Europe/Berlin')\n",
    "\n",
    "# long timestamp\n",
    "def date(x):\n",
    "    return  dt.datetime.fromtimestamp(float(x) / 1e3, tz=de)\n",
    "\n",
    "\n",
    "def adddatecolumns(data,pf,column) :\n",
    "    data['year'] = pf[column].apply(lambda x: date(x).date().year)\n",
    "    data['month'] = pf[column].apply(lambda x: date(x).date().month)\n",
    "    data['day'] = pf[column].apply(lambda x: date(x).date().day)\n",
    "    data['hour'] = pf[column].apply(lambda x: date(x).time().hour)\n",
    "    data['minute'] = pf[column].apply(lambda x: date(x).time().minute)\n",
    "    #data['second'] = pf[column].apply(lambda x: x.time().second)\n",
    "    #data['microsecond'] = pf[column].apply(lambda x: x.time().microsecond)\n",
    "\n",
    "def converttimestampcolumnn(pf,tsc) :\n",
    "    pf[tsc] = pf[tsc].apply(lambda x: dt.datetime.fromtimestamp(float(x) / 1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup charts\n",
    "import pandas as pd\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "print(\"Setup Complete\")\n",
    "\n",
    "def get_ym_string(a,b) :\n",
    "    return a + \"-\" + b\n",
    "    #return a.join([\"-\",b]) \n",
    "\n",
    "def get_ym(mdcountsall) :\n",
    "    a = mdcountsall.index.get_level_values(0).astype(str)\n",
    "    b = mdcountsall.index.get_level_values(1).astype(str)\n",
    "    return a,b\n",
    "\n",
    "def get_ymd(mdcountsall) :\n",
    "    a = mdcountsall.index.get_level_values(0).astype(str)\n",
    "    b = mdcountsall.index.get_level_values(1).astype(str)\n",
    "    c = mdcountsall.index.get_level_values(2).astype(str)\n",
    "    return a,b,c\n",
    "\n",
    "def get_ymd_string(a,b,c) :\n",
    "    return a + \"-\" + b + \"-\" + c \n",
    "\n",
    "def get_ymdh(mdcountsall) :\n",
    "    a = mdcountsall.index.get_level_values(0).astype(str)\n",
    "    b = mdcountsall.index.get_level_values(1).astype(str)\n",
    "    c = mdcountsall.index.get_level_values(2).astype(str)\n",
    "    d = mdcountsall.index.get_level_values(3).astype(str)\n",
    "    return a,b,c,d\n",
    "\n",
    "def get_ymdh_string(a,b,c,d) :\n",
    "    return a + \"-\" + b + \"-\" + c + \"-\" + d\n",
    "\n",
    "def createData_ym(pfall,month) :\n",
    "    if (month > 0) & (month < 13) :\n",
    "        mdcountsall = pfall[(pfall['month'] == month)].groupby(['year','month'])['year'].count()\n",
    "    else :\n",
    "        mdcountsall = pfall.groupby(['year','month'])['year'].count()    \n",
    "    a,b = get_ym(mdcountsall)\n",
    "    data2 = pd.DataFrame()\n",
    "    data2['date'] = get_ym_string(a,b)\n",
    "    data2['outcome'] = mdcountsall.reset_index(level=0, drop=True).reset_index()['year'].astype(int) \n",
    "    return data2\n",
    "\n",
    "def createData(pfall,month) :\n",
    "    if (month > 0) & (month < 13) :\n",
    "        mdcountsall = pfall[(pfall['month'] == month)].groupby(['year','month','day','hour'])['year'].count()\n",
    "    else :\n",
    "        mdcountsall = pfall.groupby(['year','month','day','hour'])['year'].count()    \n",
    "    a,b,c,d = get_ymdh(mdcountsall)\n",
    "    data2 = pd.DataFrame()\n",
    "    data2['date'] = get_ymdh_string(a,b,c,d)\n",
    "    data2['outcome'] =  mdcountsall.reset_index(level=0, drop=True).reset_index()['year'].astype(int)\n",
    "\n",
    "    #for pivot table\n",
    "    data2['hours'] =  d.astype(int) \n",
    "    data2['days']  =  c.astype(int) \n",
    "    return data2\n",
    "\n",
    "def createData_ymd(pfall,month) :\n",
    "    if (month > 0) & (month < 13) :\n",
    "        mdcountsall = pfall[(pfall['month'] == month)].groupby(['year','month','day'])['year'].count()\n",
    "    else :\n",
    "        mdcountsall = pfall.groupby(['year','month','day'])['year'].count()    \n",
    "    a,b,c = get_ymd(mdcountsall)\n",
    "    data2 = pd.DataFrame()\n",
    "    data2['date'] = get_ymd_string(a,b,c)\n",
    "    data2['outcome'] = mdcountsall.reset_index(level=0, drop=True).reset_index()['year'].astype(int) \n",
    "    return data2\n",
    "\n",
    "def label(graph,skip,rot) :\n",
    "    for ind, label in enumerate(graph.get_xticklabels()):\n",
    "        if ind % skip == 0:  # every 10th label is kept\n",
    "            label.set_visible(True)\n",
    "            label.set_rotation(rot)\n",
    "        else:\n",
    "            label.set_visible(False)\n",
    "\n",
    "def createBarplot(md=None,fx=24,fy=12,fontscale=3.0,title=\"\") :\n",
    "    sns.set(style='whitegrid', palette='muted', font_scale=fontscale)\n",
    "    plt.figure(figsize=(fx,fy))\n",
    "    plt.title(title)\n",
    "    ax = sns.barplot(x=md['date'], y=md['outcome'], data=md)\n",
    "    plt.setp( ax.xaxis.get_majorticklabels(), rotation=75 )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return ax\n",
    "\n",
    "## heatmap\n",
    "def createHeatmap(piv,title=\"\") :\n",
    "    plt.figure(figsize=(24,8))\n",
    "    plt.title(title)\n",
    "    ax = sns.heatmap(piv, square=True)\n",
    "    plt.setp( ax.xaxis.get_majorticklabels(), rotation=0 )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = createData_ym(pfall,0)\n",
    "ax=createBarplot(md,24,12,3.0,title=\"number messages sent by all endpoints\")\n",
    "#label(ax,1000,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = createData_ymd(pfall,1)\n",
    "ax=createBarplot(md,fx=24,fy=12,fontscale=3.0,title=\"number messages sent by all endpoints\")\n",
    "label(ax,1000,90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createHeatmapPfall(pfall=pfall,sender='all',month=1):\n",
    "    data2 = createData(pfall,month)\n",
    "    piv = pd.pivot_table(data2, values=\"outcome\",index=[\"hours\"], columns=[\"days\"], fill_value=0)\n",
    "    #titlestring = \"CSENDERENDPOINTID: \" + str(topsender.iloc[7]['CSENDERENDPOINTID']) + \": \"+ category + \" so far = \" + str(topsender.iloc[7]['outcome']) + \" , month: \" + str(month) \n",
    "    #titlestring = \"CSENDERENDPOINTID: \" + str(topsender.iloc[7]['CSENDERENDPOINTID']) + \": \"+ category  + \" month: \" + str(month) \n",
    "    titlestring =\"number messages 2020-\" + str(month) + \" sender: \" + sender\n",
    "    sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "    createHeatmap(piv, titlestring)\n",
    "    \n",
    "createHeatmapPfall(pfall=pfall,sender='all',month=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createHeatmapPfall(pfall,'all',6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top senders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.unique(mdcountsall[1].index.get_level_values(0))\n",
    "def getTopSenders(TOP):\n",
    "    result = pfall.groupby(['CSENDERENDPOINTID']).count()\n",
    "    data2 = pd.DataFrame()\n",
    "    data2['date'] = result.index.get_level_values(0).astype(str)\n",
    "    data2['outcome'] =  result['CSTARTTIME'].astype(int)\n",
    "    topsender =  data2[data2['outcome'] > TOP].sort_values('outcome', ascending=False).reset_index()\n",
    "    topsender['outcome'] = topsender['outcome'].astype(int)\n",
    "    topsender.columns = ['index', 'CSENDERENDPOINTID', 'count']\n",
    "    return topsender\n",
    "\n",
    "#topsender = getTopSenders(500000)\n",
    "topsender = getTopSenders(1000)\n",
    "topsender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbersenders = len(pfall['CSENDERENDPOINTID'].unique())\n",
    "print('sending endpoints: '  + str(numbersenders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender = topsender.iloc[0]['index']\n",
    "pfall1 = pfall[pfall['CSENDERENDPOINTID'] == sender].sort_values('CSTARTTIME').reset_index() \n",
    "\n",
    "def get_datestr(row):\n",
    "    return str(row.day) + \".\" + str(row.month) + \".\" + str(row.year) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createHeatmapPfall(pfall1,str(sender),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Anomaly Detection with LSTM Autoencoders (selected sender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = \"http://172.30.12.56:3128\" \n",
    "os.environ['https_proxy'] = \"https://172.30.12.56:3128\" \n",
    "#!pip install --trusted-host pypi.python.org pytest-xdist\n",
    "#!pip install --trusted-host pypi.python.org --upgrade pip\n",
    "#!pip install --trusted-host pypi.python.org tensorflow\n",
    "#!pip3 install --user --upgrade tensorflow \n",
    "#!pip install tensorflow==2.4.1\n",
    "#!pip install --trusted-host pypi.python.org python==3.7\n",
    "#!pip install --upgrade pip --trusted-host pypi.org --trusted-host files.pythonhosted.org\n",
    "#!pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org tensorflow==2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anomaly\n",
    "anomaly.init_sns()\n",
    "#pip3 install --trusted-host pypi.org --trusted-host files.pythonhosted.org numpy==1.18.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = anomaly.createDataframe(pfall)\n",
    "perc_train=0.94\n",
    "train, test = anomaly.getTrainAndTest(df1,perc_train)\n",
    "OUTCOME = 'close'\n",
    "scaler = anomaly.StandardScaler()\n",
    "scaler = scaler.fit(train[[OUTCOME]])\n",
    "train[OUTCOME] = scaler.transform(train[[OUTCOME]])\n",
    "test[OUTCOME] = scaler.transform(test[[OUTCOME]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 12\n",
    "X_train, y_train = anomaly.create_dataset(train[[OUTCOME]], train.close, TIME_STEPS)\n",
    "X_test, y_test = anomaly.create_dataset(test[[OUTCOME]], test.close, TIME_STEPS)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U numpy==1.18.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = anomaly.initmodel(X_train)\n",
    "\n",
    "from tensorflow import keras\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(256, input_shape=(1, 66), return_sequences=True))\n",
    "\n",
    "model.add(keras.layers.LSTM(\n",
    "    units=64, \n",
    "    input_shape=(X_train.shape[1], X_train.shape[2])\n",
    "))\n",
    " \n",
    "model.add(keras.layers.Dropout(rate=0.2))\n",
    "model.add(keras.layers.RepeatVector(n=X_train.shape[1]))\n",
    "model.add(keras.layers.LSTM(units=64, return_sequences=True))\n",
    "model.add(keras.layers.Dropout(rate=0.2))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Dense(units=X_train.shape[2])))\n",
    "model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,scaler,train,test,X_test,X_train,X_train_pred,train_mae_loss = anomaly.initAndTrain(pfall1,0.94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_mae_loss, bins=50, kde=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_df = anomaly.testScoreDF(model, 1.9,X_test,test)\n",
    "anomalies     = test_score_df[test_score_df.anomaly == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_score_df.index, test_score_df.loss, label='loss')\n",
    "plt.plot(test_score_df.index, test_score_df.threshold, label='threshold')\n",
    "plt.xticks(rotation=25)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlestring =\"endpoint (sending) : \" + str(sender) + \" ( trained: \" +  train.index[0] + \" -- \" + train.index[len(train.index)-1] + \" )\"\n",
    "anomaly.plot_test(test,scaler,anomalies,titlestring)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
